{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import  make_classification\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "print('Load data...')\n",
    "\n",
    "\n",
    "train_raw=pd.read_csv('../gdata/train.csv')\n",
    "\n",
    "# Reduce the cv dataset\n",
    "train_raw=train_raw.sample(frac=0.1)\n",
    "\n",
    "Train_Master=train_raw.drop('Unnamed: 0',axis=1)\n",
    "X_train=Train_Master.drop(['log_trip_duration'],axis=1)\n",
    "y_train=Train_Master['log_trip_duration']\n",
    "del train_raw\n",
    "del Train_Master\n",
    "\n",
    "\n",
    "# Example For iris \n",
    "# iris = load_iris()\n",
    "# data=iris.data\n",
    "# target = iris.target\n",
    "# X_train,X_test,y_train,y_test =train_test_split(data,target,test_size=0.2)\n",
    "\n",
    "# df_train = pd.read_csv('../regression/regression.train', header=None, sep='\\t')\n",
    "# df_test = pd.read_csv('../regression/regression.test', header=None, sep='\\t')\n",
    "# y_train = df_train[0].values\n",
    "# y_test = df_test[0].values\n",
    "# X_train = df_train.drop(0, axis=1).values\n",
    "# X_test = df_test.drop(0, axis=1).values\n",
    "\n",
    "gc.collect()\n",
    "X_train,X_test,y_train,y_test =train_test_split(X_train,y_train,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索，参数优化\n",
    "if(CV):\n",
    "\n",
    "    estimator = lgb.LGBMRegressor(num_leaves=31)\n",
    "\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'n_estimators': [20, 40]\n",
    "    }\n",
    "\n",
    "    gbm = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "    gbm.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters found by grid search are:', gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's l1: 0.552449\tvalid_0's l2: 0.507598\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's l1: 0.517877\tvalid_0's l2: 0.447801\n",
      "[3]\tvalid_0's l1: 0.488141\tvalid_0's l2: 0.399594\n",
      "[4]\tvalid_0's l1: 0.462291\tvalid_0's l2: 0.360176\n",
      "[5]\tvalid_0's l1: 0.440282\tvalid_0's l2: 0.328427\n",
      "[6]\tvalid_0's l1: 0.421275\tvalid_0's l2: 0.302456\n",
      "[7]\tvalid_0's l1: 0.405005\tvalid_0's l2: 0.281225\n",
      "[8]\tvalid_0's l1: 0.391081\tvalid_0's l2: 0.26377\n",
      "[9]\tvalid_0's l1: 0.379155\tvalid_0's l2: 0.249449\n",
      "[10]\tvalid_0's l1: 0.36909\tvalid_0's l2: 0.237795\n",
      "[11]\tvalid_0's l1: 0.360608\tvalid_0's l2: 0.228091\n",
      "[12]\tvalid_0's l1: 0.353381\tvalid_0's l2: 0.220159\n",
      "[13]\tvalid_0's l1: 0.347311\tvalid_0's l2: 0.213604\n",
      "[14]\tvalid_0's l1: 0.342165\tvalid_0's l2: 0.208063\n",
      "[15]\tvalid_0's l1: 0.337866\tvalid_0's l2: 0.203591\n",
      "[16]\tvalid_0's l1: 0.334073\tvalid_0's l2: 0.199828\n",
      "[17]\tvalid_0's l1: 0.330879\tvalid_0's l2: 0.196537\n",
      "[18]\tvalid_0's l1: 0.328056\tvalid_0's l2: 0.193644\n",
      "[19]\tvalid_0's l1: 0.325515\tvalid_0's l2: 0.191199\n",
      "[20]\tvalid_0's l1: 0.32338\tvalid_0's l2: 0.189144\n",
      "[21]\tvalid_0's l1: 0.321381\tvalid_0's l2: 0.187315\n",
      "[22]\tvalid_0's l1: 0.31969\tvalid_0's l2: 0.185676\n",
      "[23]\tvalid_0's l1: 0.318035\tvalid_0's l2: 0.184167\n",
      "[24]\tvalid_0's l1: 0.316779\tvalid_0's l2: 0.182956\n",
      "[25]\tvalid_0's l1: 0.315521\tvalid_0's l2: 0.181903\n",
      "[26]\tvalid_0's l1: 0.314336\tvalid_0's l2: 0.180818\n",
      "[27]\tvalid_0's l1: 0.313432\tvalid_0's l2: 0.179971\n",
      "[28]\tvalid_0's l1: 0.312591\tvalid_0's l2: 0.179156\n",
      "[29]\tvalid_0's l1: 0.311693\tvalid_0's l2: 0.178302\n",
      "[30]\tvalid_0's l1: 0.310758\tvalid_0's l2: 0.177406\n",
      "[31]\tvalid_0's l1: 0.309984\tvalid_0's l2: 0.176751\n",
      "[32]\tvalid_0's l1: 0.309263\tvalid_0's l2: 0.176166\n",
      "[33]\tvalid_0's l1: 0.308672\tvalid_0's l2: 0.175631\n",
      "[34]\tvalid_0's l1: 0.308169\tvalid_0's l2: 0.17511\n",
      "[35]\tvalid_0's l1: 0.307472\tvalid_0's l2: 0.174501\n",
      "[36]\tvalid_0's l1: 0.306774\tvalid_0's l2: 0.173856\n",
      "[37]\tvalid_0's l1: 0.306218\tvalid_0's l2: 0.173383\n",
      "[38]\tvalid_0's l1: 0.305705\tvalid_0's l2: 0.17293\n",
      "[39]\tvalid_0's l1: 0.305255\tvalid_0's l2: 0.172545\n",
      "[40]\tvalid_0's l1: 0.304702\tvalid_0's l2: 0.17202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[40]\tvalid_0's l1: 0.304702\tvalid_0's l2: 0.17202\n",
      "Start predicting...\n",
      "The rmse of prediction is: 0.41475260980978984\n",
      "Feature importances: [121, 28, 169, 11, 25, 115, 149, 43, 13, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 11, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 20, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 4, 10, 1, 0, 24, 0, 8, 0, 2, 0, 5, 0, 0, 0, 0, 3, 1, 0, 1, 0, 1, 0, 0, 5, 0, 11, 0, 0, 10, 4, 0, 3, 1, 0, 0, 1, 15, 0, 0, 0, 5, 0, 1, 4, 0, 0, 20, 0, 0, 0, 8, 0, 2, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 17, 0, 0, 5, 3, 0, 15, 0, 0, 0, 0, 0, 14, 0, 0, 0, 3, 0, 9, 2, 1, 2, 5, 2, 3, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 4, 2, 2, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 20, 4, 8, 7, 4, 28, 76]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "print('Start training...')\n",
    "# 创建模型，训练模型\n",
    "gbm_bst = lgb.LGBMRegressor(objective='regression',num_leaves=31,learning_rate=0.1,n_estimators=40)\n",
    "gbm_bst.fit(X_train, y_train,eval_set=[(X_test, y_test)],eval_metric='l1',early_stopping_rounds=5)\n",
    "\n",
    "print('Start predicting...')\n",
    "# 测试机预测\n",
    "y_pred = gbm_bst.predict(X_test, num_iteration=gbm_bst.best_iteration_)\n",
    "# 模型评估\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm_bst.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Final training\n",
    "train_raw=pd.read_csv('../gdata/train.csv')\n",
    "\n",
    "# Reduce the cv dataset\n",
    "Train_Master=train_raw.drop('Unnamed: 0',axis=1)\n",
    "X_train=Train_Master.drop(['log_trip_duration'],axis=1)\n",
    "y_train=Train_Master['log_trip_duration']\n",
    "del train_raw\n",
    "del Train_Master\n",
    "\n",
    "gbm_final = lgb.LGBMRegressor(objective='regression',num_leaves=31,learning_rate=0.1,n_estimators=40)\n",
    "gbm_final.fit(X_train, y_train,early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "import pickle\n",
    "pickle.dump(gbm_final,open('LGBM_Model.dat','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   distance_haversine  distance_dummy_manhattan   direction  pickup_cluster  \\\n",
      "0            2.746426                  2.913304   -3.595224              86   \n",
      "1            2.759239                  3.104805  172.278835               5   \n",
      "2            1.306155                  1.846340  133.326248              87   \n",
      "3            5.269088                  7.163347 -150.956833               1   \n",
      "4            0.960842                  1.354164  130.260381              22   \n",
      "\n",
      "   dropoff_cluster  total_distance  total_travel_time  number_of_steps  vi_1  \\\n",
      "0               94          3795.9              424.6                4     1   \n",
      "1               21          2904.5              200.0                4     1   \n",
      "2               86          1499.5              193.2                4     1   \n",
      "3               86          7023.9              494.8               11     0   \n",
      "4               12          1108.2              103.2                4     1   \n",
      "\n",
      "   vi_2  ...    h_21  h_22  h_23  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  \\\n",
      "0     0  ...       0     0     1      0      0      0      1      0      0   \n",
      "1     0  ...       0     0     1      0      0      0      1      0      0   \n",
      "2     0  ...       0     0     1      0      0      0      1      0      0   \n",
      "3     1  ...       0     0     1      0      0      0      1      0      0   \n",
      "4     0  ...       0     0     1      0      0      0      1      0      0   \n",
      "\n",
      "   dow_6  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n",
      "\n",
      "[5 rows x 287 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gbm_bst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ff5ca49afd3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm_bst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gbm_bst' is not defined"
     ]
    }
   ],
   "source": [
    "# read test data\n",
    "test_X=pd.read_csv('../gdata/test.csv')\n",
    "test_X=test_X.drop('Unnamed: 0',axis=1)\n",
    "print(test_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=gbm_final.predict(test_X)\n",
    "# recover log transformation log(y+1)\n",
    "pred = np.exp(prediction) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add id\n",
    "original_test=pd.read_csv('../new-york-city-taxi-with-osrm/test.csv')\n",
    "Test_id=original_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([Test_id, pd.DataFrame(pred)], axis=1)\n",
    "submission.columns = ['id','trip_duration']\n",
    "submission['trip_duration'] = submission.apply(lambda x : 1 if (x['trip_duration'] <= 0) else x['trip_duration'], axis = 1)\n",
    "submission.to_csv(\"submission_LGBM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result on Kaggle\n",
    "### First\n",
    "Dataset:\n",
    "fraction: 0.1 * 0.8\n",
    "\n",
    "Hyperparameter:\n",
    "num_leaves=31\n",
    "learning_rate=0.1\n",
    "n_estimators=40\n",
    "\n",
    "\n",
    "Name\n",
    "Submitted\n",
    "Wait time\n",
    "Execution time\n",
    "Score\n",
    "\n",
    "submission_LGBM.csv\n",
    "7 minutes ago\n",
    "1 seconds\n",
    "4 seconds\n",
    "0.45924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
